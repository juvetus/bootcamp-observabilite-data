# ğŸ³ Azure Data Factory Pipeline - Docker Deployment

## PrÃ©requis

- Docker Desktop installÃ©
- ClÃ© API Datadog

## ğŸš€ DÃ©marrage Rapide

### 1. Configurer les variables d'environnement

Assurez-vous que votre fichier `.env` contient votre clÃ© API :

```bash
DD_API_KEY=votre_cle_api_datadog
DD_SITE=datadoghq.eu
PIPELINE_NAME=docker-adf-pipeline
ENV=dev
SIMULATE_ERROR=false
ERROR_TYPE=processing
```

### 2. Lancer le pipeline avec Docker Compose

```bash
# DÃ©marrer l'agent Datadog et le pipeline
docker-compose up

# Ou en arriÃ¨re-plan
docker-compose up -d

# Voir les logs
docker-compose logs -f adf-pipeline
```

### 3. ArrÃªter les conteneurs

```bash
docker-compose down
```

## ğŸ® Utilisation

### ExÃ©cution normale

```bash
docker-compose up adf-pipeline
```

### Simuler des erreurs

```bash
# Erreur de processing
SIMULATE_ERROR=true ERROR_TYPE=processing docker-compose up adf-pipeline

# Erreur de validation
SIMULATE_ERROR=true ERROR_TYPE=validation docker-compose up adf-pipeline

# Erreur de connexion
SIMULATE_ERROR=true ERROR_TYPE=connection docker-compose up adf-pipeline
```

### RÃ©exÃ©cuter le pipeline

```bash
docker-compose restart adf-pipeline
```

### Reconstruire l'image aprÃ¨s modification du code

```bash
docker-compose build adf-pipeline
docker-compose up adf-pipeline
```

## ğŸ“‚ Volumes MontÃ©s

- `./data/output` â†’ Fichiers CSV gÃ©nÃ©rÃ©s
- `./logs` â†’ Logs du pipeline

## ğŸ” Debugging

### Voir les logs en temps rÃ©el

```bash
# Logs du pipeline
docker-compose logs -f adf-pipeline

# Logs de l'agent Datadog
docker-compose logs -f dd-agent
```

### Inspecter un conteneur

```bash
docker exec -it adf-pipeline /bin/bash
```

### VÃ©rifier le statut de l'agent Datadog

```bash
docker exec -it dd-agent-adf agent status
```

## ğŸŒ RÃ©seau

Les conteneurs communiquent via le rÃ©seau `pipeline-network` :
- Pipeline â†’ Agent Datadog (StatsD sur port 8125)
- Pipeline â†’ API Datadog (HTTPS pour les logs)

## ğŸ“Š MÃ©triques et Logs dans Datadog

Une fois lancÃ©, vÃ©rifiez dans Datadog :

**Logs** :
```
service:adf-pipeline env:dev
```

**MÃ©triques** :
```
pipeline.records_processed{pipeline:docker-adf-pipeline}
```

## ğŸ”§ Personnalisation

### Modifier les variables d'environnement

Ã‰ditez `docker-compose.yml` ou crÃ©ez un fichier `.env` :

```env
PIPELINE_NAME=mon-pipeline
ENV=production
```

### Ajouter des dÃ©pendances Python

1. Modifiez `requirements.txt`
2. Rebuild l'image : `docker-compose build`

## ğŸ¯ Avantages du DÃ©ploiement Docker

âœ… Isolation complÃ¨te  
âœ… ReproductibilitÃ©  
âœ… Facile Ã  orchestrer  
âœ… PrÃªt pour Kubernetes  
âœ… Monitoring intÃ©grÃ© avec Datadog  

## ğŸš€ Prochaines Ã‰tapes

- Ajouter un scheduler (cron) pour exÃ©cutions pÃ©riodiques
- DÃ©ployer sur Kubernetes avec Helm
- IntÃ©grer CI/CD (GitHub Actions)
- Ajouter des health checks
