#  Azure Data Factory ‚Äì Automatisation du Traitement de Donn√©es

---

##  R√©sum√© Simple

**Imaginez une usine de traitement de donn√©es** : des informations brutes entrent d'un c√¥t√©, elles sont nettoy√©es et enrichies au milieu, puis ressortent propres et utilisables de l'autre c√¥t√©. C'est exactement ce que fait ce projet !

###  L'Analogie de la Cha√Æne de Production

Pensez √† une **cha√Æne de montage automobile** :
1.  **Entr√©e** : Les pi√®ces brutes arrivent (nos fichiers CSV)
2.  **Transformation** : Les ouvriers assemblent et ajoutent des composants (notre script Python)
3.  **Sortie** : Une voiture compl√®te sort de la cha√Æne (fichier enrichi)
4.  **Contr√¥le qualit√©** : Des inspecteurs v√©rifient chaque √©tape (Datadog)

---

##  Ce Qui a √ât√© Fait

### 1. Cr√©ation d'un Robot de Traitement de Donn√©es 

**En termes simples** : Un programme qui lit automatiquement un fichier Excel (CSV), ajoute des informations utiles, et cr√©e un nouveau fichier.

**Exemple concret** :
- **Avant** : `alice, login, 10:00`
- **Apr√®s** : `alice, login, 10:00, trait√© le 30/12/2025 √† 13:00, par pipeline-adf`

C'est comme un tampon qui marque "Vu et v√©rifi√©" sur chaque ligne du document.

### 2. Installation d'un Syst√®me de Surveillance 

**Datadog** = Un tableau de bord comme celui d'une voiture qui montre :
-  Combien de temps √ßa prend
-  Combien de lignes ont √©t√© trait√©es
-  Si tout s'est bien pass√© ou s'il y a eu des erreurs
-  Des alertes si quelque chose ne va pas

### 3. Mise en Bo√Æte avec Docker 

**Docker** = Une bo√Æte magique qui contient tout le n√©cessaire pour faire fonctionner notre robot :
- Le programme Python (le cerveau)
- Les outils n√©cessaires (les mains)
- La configuration (le mode d'emploi)

**Avantage** : On peut transporter cette bo√Æte partout et elle fonctionnera de la m√™me mani√®re !

---

##  Le Contexte Technique (Vulgaris√©)

### Les Outils Utilis√©s

| Outil | Analogie | √Ä Quoi √áa Sert |
|-------|----------|-----------------|
| **Python** | Le chef cuisinier | Suit la recette pour transformer les donn√©es |
| **CSV** | Un tableau Excel | Format simple pour stocker des donn√©es |
| **Datadog** | Cam√©ras de surveillance | Surveille que tout fonctionne bien |
| **Docker** | Bo√Æte herm√©tique | Garantit que √ßa marche partout pareil |
| **Azure Data Factory** | Usine dans le cloud | Version professionnelle h√©berg√©e chez Microsoft |

---

##  Comment √áa Marche ?

### Le Processus en 3 √âtapes

```
 ENTR√âE                    üîß TRAITEMENT                     SORTIE
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Fichier events.csv           Robot Python lit                 Fichier enrichi
62 lignes d'√©v√©nements  ‚Üí    Ajoute date + source      ‚Üí     62 lignes + infos
(login, logout, error)       Compte et v√©rifie                Pr√™t √† utiliser
```

### Exemple R√©el de Transformation

**Fichier d'entr√©e** (ce qu'on a au d√©part) :
```
id | type   | utilisateur | heure
1  | login  | alice       | 10:00
2  | logout | bob         | 10:05
```

**Fichier de sortie** (ce qu'on obtient) :
```
id | type   | utilisateur | heure | date_traitement           | source_pipeline
1  | login  | alice       | 10:00 | 2025-12-30T13:00:00      | docker-adf-pipeline
2  | logout | bob         | 10:05 | 2025-12-30T13:00:00      | docker-adf-pipeline
```

**Ce qui a √©t√© ajout√©** :
-  **date_traitement** : Quand le fichier a √©t√© trait√© (pour tra√ßabilit√©)
-  **source_pipeline** : Quel robot a fait le travail (pour l'audit)

---

##  Les M√©triques : Voir Ce Qui Se Passe

### Tableau de Bord (Dashboard)

Imaginez le **compteur kilom√©trique d'une voiture** qui affiche :

|  M√©trique |  Signification |  Exemple |
|------------|-----------------|-----------|
| **Records trait√©s** | Nombre de lignes lues | 60 lignes |
| **Dur√©e** | Temps pour tout traiter | 0.25 seconde |
| **Taux de succ√®s** | Pourcentage sans erreur | 100%  |
| **Vitesse** | Lignes par seconde | 240 lignes/sec |
| **Erreurs** | Nombre de probl√®mes | 0 erreur |

### Graphiques Visuels

Dans Datadog, vous voyez des **graphiques en temps r√©el** comme :
-  Une courbe de la vitesse de traitement
-  Un camembert des types d'√©v√©nements (login vs logout vs error)
-  Des feux tricolores : vert = OK, rouge = probl√®me

---

##  Syst√®me d'Alerte Intelligent

### Comment √áa Fonctionne ?

C'est comme une **alarme incendie** dans un b√¢timent :

1. **Situation normale** 
   - Le pipeline tourne
   - Tout fonctionne bien
   - Indicateurs au vert

2. **Alerte warning** 
   - Le traitement prend plus de 5 secondes (normalement < 1s)
   - ‚Üí Email ou SMS envoy√© : " Performance d√©grad√©e"

3. **Alerte critique** 
   - Le pipeline √©choue compl√®tement
   - ‚Üí Notification imm√©diate : " Pipeline en √©chec, intervention requise"

### Tests de Simulation d'Erreurs

Le syst√®me peut **simuler des pannes** pour tester les alertes :

| Type d'Erreur | Simulation | R√©action du Syst√®me |
|---------------|------------|---------------------|
| **Connexion** | Le fichier n'est pas accessible |  Arr√™t imm√©diat + alerte |
| **Validation** | Une ligne a un format invalide |  Ligne ignor√©e + warning |
| **Traitement** | Bug dans le code |  Arr√™t + stacktrace dans les logs |

---

##  Le D√©ploiement Docker

### Pourquoi Docker ?

**Analogie** : Docker = Un **conteneur de transport maritime**

Sans Docker :
-  "√áa marche sur mon PC mais pas sur le serveur"
-  "Il manque une biblioth√®que Python"
-  "La version n'est pas la bonne"

Avec Docker :
-  Tout est emball√© dans le conteneur
-  Fonctionne partout de la m√™me fa√ßon
-  Facile √† d√©marrer : `docker compose up`

### Architecture Docker

```
 Conteneur 1 : Agent Datadog
   ‚Üí Collecte les m√©triques
   ‚Üí Envoie √† Datadog Cloud
   
 Conteneur 2 : Pipeline Python
   ‚Üí Lit le CSV
   ‚Üí Transforme les donn√©es
   ‚Üí Envoie les stats √† l'agent
   
 R√©seau Docker
   ‚Üí Les 2 conteneurs communiquent
```

---

##  Images Sugg√©r√©es

### 1. Architecture Simplifi√©e
Un sch√©ma avec 3 bo√Ætes et des fl√®ches :
```
[ CSV Entr√©e] ‚Üí [ Robot Python] ‚Üí [ CSV Sortie]
                        ‚Üì
                   [ Datadog]
```

### 2. Avant/Apr√®s
Capture c√¥te √† c√¥te des fichiers CSV pour montrer la transformation

### 3. Dashboard Datadog
Tableau de bord color√© avec graphiques et indicateurs

### 4. Logs dans le Terminal
Terminal avec messages "Pipeline started" et "Pipeline finished successfully"

---

##  R√©sultats Concrets

### Performance

 **60 lignes trait√©es en 0.25 seconde**
- √âquivalent de 240 lignes par seconde
- Temps de traitement moyen : 0.01 ms par ligne
- 100% de r√©ussite

### Fiabilit√©

 **Syst√®me robuste avec 3 niveaux de protection** :
1. **V√©rification avant traitement** : Le fichier existe-t-il ?
2. **Contr√¥le pendant** : Chaque ligne est-elle valide ?
3. **Validation apr√®s** : Le fichier de sortie est-il correct ?

### Tra√ßabilit√©

 **Chaque ex√©cution est identifi√©e** :
- ID unique : `exec:8469c7c5`
- Tous les logs et m√©triques sont li√©s
- Permet de retrouver ce qui s'est pass√© √† un moment pr√©cis

---

##  Ce Que Ce Projet D√©montre

### Comp√©tences Techniques

1. **Automatisation** : Cr√©er des processus qui tournent seuls
2. **Qualit√©** : V√©rifier et valider les donn√©es
3. **Surveillance** : Savoir ce qui se passe en temps r√©el
4. **Containerisation** : Empaqueter une application pour la production

### Valeur Business

 **ROI (Retour sur Investissement)** :
- **Temps gagn√©** : Plus besoin de traiter manuellement
- **Fiabilit√©** : Moins d'erreurs humaines
- **Rapidit√©** : 240 lignes/seconde vs traitement manuel
- **Visibilit√©** : On sait toujours o√π on en est

### √âvolutivit√©

 **Pr√™t pour la mise √† l'√©chelle** :
-  Fonctionne sur 60 lignes
-  Peut traiter 60 000 lignes
-  Peut √™tre d√©ploy√© sur Azure Cloud
-  Peut tourner 24/7 automatiquement

---

##  Migration vers Azure Cloud

### La Prochaine √âtape

Ce projet **local** (sur votre ordinateur) est la **maquette** d'un syst√®me **production** (dans le cloud).

**Analogie** : C'est comme construire une **maquette de pont** avant de construire le vrai pont !

### Correspondance Local ‚Üí Cloud

|  Version Locale |  Version Cloud Azure |
|-------------------|----------------------|
| Script Python sur PC | Azure Data Factory |
| Fichier CSV local | Azure Blob Storage |
| Docker local | Azure Container Instances |
| Datadog Dashboard | Azure Monitor |

**Le code reste le m√™me**, seul l'environnement change !

---

##  Section Technique D√©taill√©e

###  Structure du projet

```
azure-data-factory/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ input/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ events.csv              # Donn√©es sources (60 √©v√©nements)
‚îÇ   ‚îî‚îÄ‚îÄ output/
‚îÇ       ‚îî‚îÄ‚îÄ events_processed.csv    # Donn√©es enrichies
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ transform.py               # Script de transformation principal
‚îÇ
‚îú‚îÄ‚îÄ logs/                          # Logs de l'application
‚îú‚îÄ‚îÄ docker-compose.yml            # Orchestration des services
‚îú‚îÄ‚îÄ Dockerfile                    # Image Python du pipeline
‚îú‚îÄ‚îÄ entrypoint.sh                 # Script de d√©marrage
‚îú‚îÄ‚îÄ requirements.txt              # D√©pendances Python
‚îú‚îÄ‚îÄ .env                         # Variables d'environnement
‚îî‚îÄ‚îÄ note.md                      # Documentation
```

---

##  Script de Transformation (transform.py)

### Vue d'ensemble

Script Python de 195 lignes qui impl√©mente un pipeline ETL complet avec observabilit√© Datadog.

### Fonctionnalit√©s principales

#### 1. **Initialisation et Configuration**

```python
# G√©n√©ration d'un execution_id unique pour tra√ßabilit√©
EXECUTION_ID = str(uuid.uuid4())[:8]

# Tags communs pour toutes les m√©triques
COMMON_TAGS = [
    f"pipeline:{PIPELINE_NAME}", 
    f"execution_id:{EXECUTION_ID}", 
    "env:dev"
]
```

#### 2. **Logging vers Datadog**

Custom handler pour envoyer les logs directement √† Datadog Logs :

```python
class DatadogLogHandler(logging.Handler):
    def emit(self, record):
        log_entry = {
            "ddsource": "python",
            "ddtags": f"env:dev,service:adf-pipeline,execution_id:{execution_id}",
            "message": self.format(record),
            "execution_id": self.execution_id,
            "pipeline": PIPELINE_NAME
        }
        # POST vers https://http-intake.logs.datadoghq.eu/api/v2/logs
```

**Avantages** :
- Logs centralis√©s dans Datadog
- Corr√©lation automatique avec les m√©triques via `execution_id`
- Recherche et filtrage avanc√©s

#### 3. **Lecture et Transformation CSV**

```python
with open("data/input/events.csv") as infile, \
     open("data/output/events_processed.csv", "w") as outfile:
    
    reader = csv.DictReader(infile)
    fieldnames = reader.fieldnames + ["processed_at", "pipeline"]
    writer = csv.DictWriter(outfile, fieldnames=fieldnames)
    
    for row in reader:
        # Enrichissement
        row["processed_at"] = datetime.now(timezone.utc).isoformat()
        row["pipeline"] = PIPELINE_NAME
        writer.writerow(row)
        
        # M√©triques par record
        statsd.timing("pipeline.record_processing_time", duration_ms)
```

#### 4. **Comptage par type d'√©v√©nement**

```python
event_types = {}  # Dictionnaire de comptage

for row in reader:
    event_type = row.get('event_type', 'unknown')
    event_types[event_type] = event_types.get(event_type, 0) + 1

# Envoi des m√©triques
for event_type, count in event_types.items():
    statsd.gauge("pipeline.events_by_type", count, 
                 tags=COMMON_TAGS + [f"event_type:{event_type}"])
```

#### 5. **Simulation d'erreurs (pour tests)**

```python
# Variables d'environnement
SIMULATE_ERROR = os.getenv("SIMULATE_ERROR", "false").lower() == "true"
ERROR_TYPE = os.getenv("ERROR_TYPE", "processing")

# Types d'erreurs simulables
if ERROR_TYPE == "connection":
    raise ConnectionError("Failed to connect to data source")
    
if ERROR_TYPE == "validation":
    # Erreur au 10√®me enregistrement
    continue
    
if ERROR_TYPE == "processing":
    # Erreur au 30√®me enregistrement
    raise ValueError("Cannot process record")
```

#### 6. **M√©triques de performance**

```python
# Calcul des statistiques
avg_processing_time = sum(processing_times) / len(processing_times)
max_processing_time = max(processing_times)
min_processing_time = min(processing_times)
throughput = records / duration

# Envoi √† Datadog
statsd.gauge("pipeline.throughput_records_per_second", throughput)
statsd.gauge("pipeline.avg_record_processing_time_ms", avg_time_ms)
statsd.gauge("pipeline.max_record_processing_time_ms", max_time_ms)
```

#### 7. **M√©triques de qualit√©**

```python
error_rate = (errors / records * 100) if records > 0 else 0
success_rate = 100 - error_rate

statsd.gauge("pipeline.error_rate_percent", error_rate)
statsd.gauge("pipeline.success_rate_percent", success_rate)
statsd.gauge("pipeline.records_success", records - errors)
statsd.gauge("pipeline.records_errors", errors)
```

#### 8. **Gestion d'erreurs compl√®te**

```python
try:
    # Traitement normal
    process_data()
    statsd.increment("pipeline.success", tags=COMMON_TAGS)
    
except Exception as e:
    error_type_name = type(e).__name__
    
    # M√©triques d'√©chec enrichies
    statsd.increment("pipeline.error", 
                     tags=COMMON_TAGS + [f"error_type:{error_type_name}"])
    statsd.gauge("pipeline.records_before_failure", records)
    statsd.gauge("pipeline.completion_rate_percent", completion_rate)
    
    logging.error(f"Pipeline failed: {str(e)}", exc_info=True)
    raise
```

---

##  M√©triques Datadog collect√©es

### Tableau complet des m√©triques

| M√©trique | Type | Description | Tags |
|----------|------|-------------|------|
| `pipeline.started` | Counter | D√©marrage du pipeline | pipeline, execution_id, env |
| `pipeline.success` | Counter | Pipeline termin√© avec succ√®s | pipeline, execution_id, env |
| `pipeline.error` | Counter | Pipeline en √©chec | pipeline, execution_id, env, error_type |
| `pipeline.records_processed` | Gauge | Nombre total d'enregistrements | pipeline, execution_id, env |
| `pipeline.records_success` | Gauge | Enregistrements trait√©s avec succ√®s | pipeline, execution_id, env |
| `pipeline.records_errors` | Gauge | Enregistrements en erreur | pipeline, execution_id, env |
| `pipeline.duration_seconds` | Gauge | Dur√©e totale du pipeline (s) | pipeline, execution_id, env |
| `pipeline.throughput_records_per_second` | Gauge | D√©bit (records/sec) | pipeline, execution_id, env |
| `pipeline.record_processing_time` | Timing | Temps par enregistrement (ms) | pipeline, execution_id, env |
| `pipeline.avg_record_processing_time_ms` | Gauge | Temps moyen par record | pipeline, execution_id, env |
| `pipeline.max_record_processing_time_ms` | Gauge | Temps max par record | pipeline, execution_id, env |
| `pipeline.min_record_processing_time_ms` | Gauge | Temps min par record | pipeline, execution_id, env |
| `pipeline.error_rate_percent` | Gauge | Taux d'erreur (%) | pipeline, execution_id, env |
| `pipeline.success_rate_percent` | Gauge | Taux de succ√®s (%) | pipeline, execution_id, env |
| `pipeline.events_by_type` | Gauge | Compteur par type d'√©v√©nement | pipeline, execution_id, env, event_type |
| `pipeline.completion_rate_percent` | Gauge | Taux de compl√©tion avant √©chec | pipeline, execution_id, env |
| `pipeline.records_before_failure` | Gauge | Records trait√©s avant √©chec | pipeline, execution_id, env |
| `pipeline.connection_error` | Counter | Erreurs de connexion | pipeline, execution_id, env |
| `pipeline.validation_error` | Counter | Erreurs de validation | pipeline, execution_id, env, event_type |
| `pipeline.processing_error` | Counter | Erreurs de traitement | pipeline, execution_id, env |

### Types de m√©triques

- **Counter** : Incr√©ment√© √† chaque occurrence (succ√®s, erreurs)
- **Gauge** : Valeur instantan√©e (nombre de records, dur√©e)
- **Timing** : Distribution de temps (processing time par record)

---

##  Configuration Docker compl√®te

### docker-compose.yml

```yaml
services:
  # Agent Datadog pour collecte des m√©triques et logs
  dd-agent:
    image: gcr.io/datadoghq/agent:7
    container_name: dd-agent-adf
    environment:
      - DD_API_KEY=${DD_API_KEY}
      - DD_SITE=${DD_SITE:-datadoghq.eu}
      - DD_HOSTNAME=docker-host
      - DD_DOGSTATSD_NON_LOCAL_TRAFFIC=true  # Accepte m√©triques des containers
      - DD_APM_ENABLED=true
      - DD_LOGS_ENABLED=true
      - DD_LOGS_CONFIG_CONTAINER_COLLECT_ALL=true
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /proc/:/host/proc/:ro
      - /sys/fs/cgroup/:/host/sys/fs/cgroup:ro
    networks:
      - pipeline-network
    healthcheck:
      test: ["CMD", "agent", "health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Pipeline ETL Python
  adf-pipeline:
    build: .
    container_name: adf-pipeline
    environment:
      - DD_AGENT_HOST=dd-agent           # Nom du service agent
      - DD_STATSD_PORT=8125
      - DD_API_KEY=${DD_API_KEY}
      - DD_SITE=${DD_SITE:-datadoghq.eu}
      - PIPELINE_NAME=${PIPELINE_NAME:-docker-adf-pipeline}
      - ENV=${ENV:-dev}
      - SIMULATE_ERROR=${SIMULATE_ERROR:-false}
      - ERROR_TYPE=${ERROR_TYPE:-processing}
    volumes:
      - ./data/output:/app/data/output
      - ./logs:/app/logs
    depends_on:
      dd-agent:
        condition: service_healthy        # Attend que l'agent soit pr√™t
    networks:
      - pipeline-network

networks:
  pipeline-network:
    driver: bridge
```

### Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Installation des d√©pendances syst√®me
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Installation des d√©pendances Python
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copie des fichiers
COPY scripts/ ./scripts/
COPY data/input/ ./data/input/
COPY entrypoint.sh .

RUN chmod +x entrypoint.sh

# Cr√©ation des dossiers
RUN mkdir -p data/output logs

CMD ["./entrypoint.sh"]
```

### requirements.txt

```txt
datadog==0.49.1
python-dotenv==1.0.0
requests==2.31.0
```

### Variables d'environnement (.env)

```env
# Datadog
DD_API_KEY=votre_cle_api_datadog
DD_SITE=datadoghq.eu

# Pipeline
PIPELINE_NAME=docker-adf-pipeline
ENV=dev

# Simulation d'erreurs (pour tests)
SIMULATE_ERROR=false
ERROR_TYPE=processing  # connection, validation, processing
```

---

##  Commandes de d√©marrage

### Ex√©cution normale

```bash
cd azure-data-factory

# Cr√©er le fichier .env
cp .env.example .env
# √âditer .env avec votre cl√© API Datadog

# Lancer le pipeline
docker-compose up --build

# Voir les logs en temps r√©el
docker-compose logs -f adf-pipeline

# Arr√™ter
docker-compose down
```

### Tests de simulation d'erreurs

#### 1. Erreur de connexion
```bash
# Modifier .env
SIMULATE_ERROR=true
ERROR_TYPE=connection

docker-compose up

# R√©sultat attendu :
# - Pipeline √©choue imm√©diatement
# - M√©trique: pipeline.connection_error = 1
# - Logs: "Connection to data source failed"
```

#### 2. Erreur de validation
```bash
SIMULATE_ERROR=true
ERROR_TYPE=validation

docker-compose up

# R√©sultat attendu :
# - Pipeline continue malgr√© l'erreur
# - 1 enregistrement ignor√© (le 10√®me)
# - M√©trique: pipeline.validation_error = 1
# - pipeline.records_success = 59 (au lieu de 60)
```

#### 3. Erreur de processing
```bash
SIMULATE_ERROR=true
ERROR_TYPE=processing

docker-compose up

# R√©sultat attendu :
# - Pipeline √©choue au 30√®me enregistrement
# - M√©trique: pipeline.records_before_failure = 30
# - M√©trique: pipeline.completion_rate_percent = 50%
# - Logs: "Processing error at record 30"
```

---

##  Dashboards et Monitoring

### Widgets recommand√©s pour Datadog

#### 1. Pipeline Executions (Timeseries)
- M√©trique : `pipeline.started` (counter - rate)
- Visualisation : Line chart
- Permet de voir le nombre d'ex√©cutions par heure/jour

#### 2. Success vs Error Rate (Query Value)
- M√©trique : `pipeline.success_rate_percent`
- Visualisation : Gauge avec threshold
- Vert > 95%, Jaune > 90%, Rouge < 90%

#### 3. Throughput (Query Value)
- M√©trique : `pipeline.throughput_records_per_second`
- Visualisation : Big Number
- Affiche les records/seconde

#### 4. Processing Time Distribution (Timeseries)
- M√©triques :
  - `pipeline.avg_record_processing_time_ms` (moyenne)
  - `pipeline.max_record_processing_time_ms` (max)
  - `pipeline.min_record_processing_time_ms` (min)
- Visualisation : Multi-line chart

#### 5. Events by Type (Pie Chart)
- M√©trique : `pipeline.events_by_type`
- Group by : `event_type`
- Visualisation : Donut chart
- Montre la r√©partition login/logout/error

#### 6. Error Rate Trend (Timeseries)
- M√©trique : `pipeline.error_rate_percent`
- Visualisation : Area chart avec threshold rouge √† 5%

#### 7. Recent Executions (Table)
- M√©triques :
  - `pipeline.records_processed`
  - `pipeline.duration_seconds`
  - `pipeline.success_rate_percent`
- Group by : `execution_id`
- Top 10 derni√®res ex√©cutions

#### 8. Logs Stream
- Source : Logs
- Query : `service:adf-pipeline`
- Colonnes : timestamp, status, message, execution_id
- Live tail activ√©

---

##  Monitors et Alertes recommand√©s

### 1. Monitor : Pipeline Failure

```
Metric: pipeline.error (counter)
Condition: sum > 0 for 1 evaluation
Alert message: 
  " Pipeline {{pipeline.name}} failed
   Execution ID: {{execution_id.name}}
   Error type: {{error_type.name}}"
Priority: Critical
```

### 2. Monitor : High Error Rate

```
Metric: pipeline.error_rate_percent
Condition: > 5% for 2 consecutive evaluations
Alert message:
  " Error rate is {{value}}% (threshold: 5%)
   Pipeline: {{pipeline.name}}"
Priority: High
```

### 3. Monitor : Slow Processing

```
Metric: pipeline.duration_seconds
Condition: > 5 seconds for 3 evaluations
Alert message:
  " Pipeline duration is {{value}}s (expected < 1s)
   Execution ID: {{execution_id.name}}"
Priority: Medium
```

### 4. Monitor : Low Throughput

```
Metric: pipeline.throughput_records_per_second
Condition: < 100 for 2 evaluations
Alert message:
  " Throughput is {{value}} records/sec (expected > 200)"
Priority: Low
```

### 5. Monitor : No Execution

```
Metric: pipeline.started (counter)
Condition: no data for 1 hour
Alert message:
  " No pipeline execution detected in the last hour"
Priority: Medium
```

---

##  Validation des r√©sultats

### V√©rification des fichiers

```bash
# Compter les lignes input
wc -l data/input/events.csv
# R√©sultat : 61 (60 + header)

# Compter les lignes output
wc -l data/output/events_processed.csv
# R√©sultat : 61 (60 + header)

# V√©rifier l'enrichissement
head -n 3 data/output/events_processed.csv
# Colonnes suppl√©mentaires: processed_at, pipeline
```

### V√©rification des m√©triques dans Datadog

```bash
# Recherche dans Metrics Explorer
pipeline.records_processed{pipeline:docker-adf-pipeline}
# Valeur attendue : 60

pipeline.success_rate_percent{pipeline:docker-adf-pipeline}
# Valeur attendue : 100.0

pipeline.duration_seconds{pipeline:docker-adf-pipeline}
# Valeur attendue : ~0.25s
```

### V√©rification des logs dans Datadog

```bash
# Recherche dans Logs Explorer
service:adf-pipeline execution_id:*

# Logs attendus :
# - "Pipeline docker-adf-pipeline started"
# - "‚Üí login: X events"
# - "‚Üí logout: Y events"  
# - "‚Üí error: Z events"
# - "Pipeline finished successfully"
```

---

##  Cas d'usage et extensions

### Migration vers Azure Cloud

| Composant Local | √âquivalent Azure | Migration |
|-----------------|------------------|-----------|
| `transform.py` | Azure Data Factory Pipeline | Copier la logique dans Copy Activity + Data Flow |
| CSV local | Azure Blob Storage | Upload via Azure Storage Explorer |
| Docker | Azure Container Instances | D√©ployer l'image Docker |
| Datadog | Azure Monitor | Int√©gration Datadog-Azure ou migration compl√®te |

### Extensions possibles

#### Court terme
- [ ] Ajouter plus de transformations (filtres, agr√©gations)
- [ ] Impl√©menter la validation des donn√©es (sch√©ma)
- [ ] Ajouter des tests unitaires (pytest)
- [ ] Cr√©er un dashboard Datadog complet

#### Moyen terme
- [ ] Planification avec Azure Data Factory Triggers
- [ ] Int√©gration avec Azure Blob Storage
- [ ] Pipeline multi-√©tapes (ingestion ‚Üí transformation ‚Üí chargement)
- [ ] Gestion des √©checs et retry logic

#### Long terme
- [ ] Migration compl√®te vers Azure Data Factory
- [ ] Int√©gration avec Azure Synapse Analytics
- [ ] Data lineage et governance
- [ ] CI/CD avec Azure DevOps

---

##  Ressources techniques

### Azure Data Factory
- [Documentation officielle](https://learn.microsoft.com/azure/data-factory/)
- [Tutoriels](https://learn.microsoft.com/azure/data-factory/tutorial-copy-data-portal)
- [Best Practices](https://learn.microsoft.com/azure/data-factory/concepts-data-flow-best-practices)

### Datadog
- [Python Integration](https://docs.datadoghq.com/developers/community/libraries/)
- [DogStatsD](https://docs.datadoghq.com/developers/dogstatsd/)
- [Log Management](https://docs.datadoghq.com/logs/)

### Docker
- [Best practices](https://docs.docker.com/develop/dev-best-practices/)
- [Docker Compose](https://docs.docker.com/compose/)

---

##  Checklist de v√©rification

### Code Quality
- [x] Variables d'environnement pour configuration
- [x] Logging structur√© avec contexte
- [x] Gestion d'erreurs compl√®te avec try/except
- [x] M√©triques sur tous les points critiques
- [x] Tags coh√©rents sur toutes les m√©triques
- [x] Documentation inline (docstrings)

### Observabilit√©
- [x] M√©triques de volum√©trie (records trait√©s)
- [x] M√©triques de performance (dur√©e, throughput)
- [x] M√©triques de qualit√© (error rate, success rate)
- [x] M√©triques m√©tier (events by type)
- [x] Logs centralis√©s dans Datadog
- [x] Corr√©lation logs/m√©triques via execution_id

### Infrastructure
- [x] Docker multi-services (agent + pipeline)
- [x] Health checks configur√©s
- [x] Volumes pour persistance
- [x] R√©seau Docker d√©di√©
- [x] Variables d'environnement externalis√©es

### Tests
- [x] Test nominal (60 records, 0 erreur)
- [x] Test erreur connexion
- [x] Test erreur validation
- [x] Test erreur processing
- [x] V√©rification m√©triques Datadog

---

##  √Ä Qui √áa Sert ?

### Cas d'Usage R√©els

1. **Service RH** : Traiter automatiquement les relev√©s de pr√©sence
2. **Service Finance** : Consolider les rapports de ventes journaliers
3. **Service IT** : Analyser les logs de connexion
4. **Service Client** : Extraire les statistiques de satisfaction

### Exemple Concret Mercedes-Benz

Imaginons l'utilisation dans un contexte automobile :
- **Entr√©e** : Logs des capteurs de camions (temp√©rature, vitesse, GPS)
- **Traitement** : Enrichissement avec donn√©es m√©t√©o et trafic
- **Sortie** : Alertes pr√©dictives de maintenance
- **Surveillance** : Dashboard temps r√©el du parc de v√©hicules

---

##  Livrables du Projet

### Ce Qui Est Fourni

-  **Code source complet** : Pr√™t √† √™tre ex√©cut√©
-  **Configuration Docker** : D√©ploiement en 1 commande
-  **Documentation d√©taill√©e** : Comment l'utiliser
-  **Exemples de donn√©es** : Pour tester imm√©diatement
-  **Logs et m√©triques** : Visibles dans Datadog

### Comment L'Utiliser

```bash
# 1. T√©l√©charger le projet
git clone [repo]

# 2. Configurer votre cl√© Datadog
# √âditer le fichier .env

# 3. Lancer
docker compose up

# 4. Voir les r√©sultats
# ‚Üí Fichier : data/output/events_processed.csv
# ‚Üí Dashboard : app.datadoghq.eu
```

---

##  Points Cl√©s √† Retenir

### En 3 Phrases

1.  **Un robot lit un fichier, ajoute des infos utiles, et cr√©e un nouveau fichier**
2.  **Un syst√®me de surveillance (Datadog) v√©rifie que tout fonctionne bien**
3.  **Tout est empaquet√© dans Docker pour fonctionner partout de la m√™me fa√ßon**

### Pourquoi C'est Important

-  **Pour l'entreprise** : Gain de temps et fiabilit√©
-  **Pour l'apprentissage** : Comprendre les pipelines de donn√©es modernes
-  **Pour la carri√®re** : Comp√©tences demand√©es en DevOps/Data Engineering

---

##  Auteur

**Juvet**  
DevOps Engineer ‚Äì Mercedes-Benz Trucks Molsheim

*Projet r√©alis√© dans le cadre du Bootcamp Observabilit√© & Data*  
*P√©riode : 27 d√©cembre 2025 ‚Üí 19 janvier 2026*
