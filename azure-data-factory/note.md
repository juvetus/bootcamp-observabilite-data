# â˜ï¸ Azure Data Factory â€“ Automatisation du Traitement de DonnÃ©es

---

## ğŸ“‹ RÃ©sumÃ© Simple

**Imaginez une usine de traitement de donnÃ©es** : des informations brutes entrent d'un cÃ´tÃ©, elles sont nettoyÃ©es et enrichies au milieu, puis ressortent propres et utilisables de l'autre cÃ´tÃ©. C'est exactement ce que fait ce projet !

### ğŸ¬ L'Analogie de la ChaÃ®ne de Production

Pensez Ã  une **chaÃ®ne de montage automobile** :
1. ğŸš— **EntrÃ©e** : Les piÃ¨ces brutes arrivent (nos fichiers CSV)
2. ğŸ”§ **Transformation** : Les ouvriers assemblent et ajoutent des composants (notre script Python)
3. âœ… **Sortie** : Une voiture complÃ¨te sort de la chaÃ®ne (fichier enrichi)
4. ğŸ“Š **ContrÃ´le qualitÃ©** : Des inspecteurs vÃ©rifient chaque Ã©tape (Datadog)

---

## ğŸ¯ Ce Qui a Ã‰tÃ© Fait

### 1. CrÃ©ation d'un Robot de Traitement de DonnÃ©es ğŸ¤–

**En termes simples** : Un programme qui lit automatiquement un fichier Excel (CSV), ajoute des informations utiles, et crÃ©e un nouveau fichier.

**Exemple concret** :
- **Avant** : `alice, login, 10:00`
- **AprÃ¨s** : `alice, login, 10:00, traitÃ© le 30/12/2025 Ã  13:00, par pipeline-adf`

C'est comme un tampon qui marque "Vu et vÃ©rifiÃ©" sur chaque ligne du document.

### 2. Installation d'un SystÃ¨me de Surveillance ğŸ‘ï¸

**Datadog** = Un tableau de bord comme celui d'une voiture qui montre :
- â±ï¸ Combien de temps Ã§a prend
- ğŸ“Š Combien de lignes ont Ã©tÃ© traitÃ©es
- âœ… Si tout s'est bien passÃ© ou s'il y a eu des erreurs
- ğŸ”” Des alertes si quelque chose ne va pas

### 3. Mise en BoÃ®te avec Docker ğŸ“¦

**Docker** = Une boÃ®te magique qui contient tout le nÃ©cessaire pour faire fonctionner notre robot :
- Le programme Python (le cerveau)
- Les outils nÃ©cessaires (les mains)
- La configuration (le mode d'emploi)

**Avantage** : On peut transporter cette boÃ®te partout et elle fonctionnera de la mÃªme maniÃ¨re !

---

## ğŸŒ Le Contexte Technique (VulgarisÃ©)

### Les Outils UtilisÃ©s

| Outil | Analogie | Ã€ Quoi Ã‡a Sert |
|-------|----------|-----------------|
| **Python** | Le chef cuisinier | Suit la recette pour transformer les donnÃ©es |
| **CSV** | Un tableau Excel | Format simple pour stocker des donnÃ©es |
| **Datadog** | CamÃ©ras de surveillance | Surveille que tout fonctionne bien |
| **Docker** | BoÃ®te hermÃ©tique | Garantit que Ã§a marche partout pareil |
| **Azure Data Factory** | Usine dans le cloud | Version professionnelle hÃ©bergÃ©e chez Microsoft |

---

## ğŸ”„ Comment Ã‡a Marche ?

### Le Processus en 3 Ã‰tapes

```
ğŸ“¥ ENTRÃ‰E                    ğŸ”§ TRAITEMENT                    ğŸ“¤ SORTIE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Fichier events.csv           Robot Python lit                 Fichier enrichi
62 lignes d'Ã©vÃ©nements  â†’    Ajoute date + source      â†’     62 lignes + infos
(login, logout, error)       Compte et vÃ©rifie                PrÃªt Ã  utiliser
```

### Exemple RÃ©el de Transformation

**Fichier d'entrÃ©e** (ce qu'on a au dÃ©part) :
```
id | type   | utilisateur | heure
1  | login  | alice       | 10:00
2  | logout | bob         | 10:05
```

**Fichier de sortie** (ce qu'on obtient) :
```
id | type   | utilisateur | heure | date_traitement           | source_pipeline
1  | login  | alice       | 10:00 | 2025-12-30T13:00:00      | docker-adf-pipeline
2  | logout | bob         | 10:05 | 2025-12-30T13:00:00      | docker-adf-pipeline
```

**Ce qui a Ã©tÃ© ajoutÃ©** :
- â° **date_traitement** : Quand le fichier a Ã©tÃ© traitÃ© (pour traÃ§abilitÃ©)
- ğŸ·ï¸ **source_pipeline** : Quel robot a fait le travail (pour l'audit)

---

## ğŸ“Š Les MÃ©triques : Voir Ce Qui Se Passe

### Tableau de Bord (Dashboard)

Imaginez le **compteur kilomÃ©trique d'une voiture** qui affiche :

| ğŸ¯ MÃ©trique | ğŸ“ Signification | ğŸ”¢ Exemple |
|------------|-----------------|-----------|
| **Records traitÃ©s** | Nombre de lignes lues | 60 lignes |
| **DurÃ©e** | Temps pour tout traiter | 0.25 seconde |
| **Taux de succÃ¨s** | Pourcentage sans erreur | 100% âœ… |
| **Vitesse** | Lignes par seconde | 240 lignes/sec |
| **Erreurs** | Nombre de problÃ¨mes | 0 erreur |

### Graphiques Visuels

Dans Datadog, vous voyez des **graphiques en temps rÃ©el** comme :
- ğŸ“ˆ Une courbe de la vitesse de traitement
- ğŸ© Un camembert des types d'Ã©vÃ©nements (login vs logout vs error)
- ğŸš¦ Des feux tricolores : vert = OK, rouge = problÃ¨me

---

## ğŸš¨ SystÃ¨me d'Alerte Intelligent

### Comment Ã‡a Fonctionne ?

C'est comme une **alarme incendie** dans un bÃ¢timent :

1. **Situation normale** ğŸŸ¢
   - Le pipeline tourne
   - Tout fonctionne bien
   - Indicateurs au vert

2. **Alerte warning** ğŸŸ¡
   - Le traitement prend plus de 5 secondes (normalement < 1s)
   - â†’ Email ou SMS envoyÃ© : "âš ï¸ Performance dÃ©gradÃ©e"

3. **Alerte critique** ğŸ”´
   - Le pipeline Ã©choue complÃ¨tement
   - â†’ Notification immÃ©diate : "ğŸš¨ Pipeline en Ã©chec, intervention requise"

### Tests de Simulation d'Erreurs

Le systÃ¨me peut **simuler des pannes** pour tester les alertes :

| Type d'Erreur | Simulation | RÃ©action du SystÃ¨me |
|---------------|------------|---------------------|
| **Connexion** | Le fichier n'est pas accessible | âŒ ArrÃªt immÃ©diat + alerte |
| **Validation** | Une ligne a un format invalide | âš ï¸ Ligne ignorÃ©e + warning |
| **Traitement** | Bug dans le code | âŒ ArrÃªt + stacktrace dans les logs |

---

## ğŸ³ Le DÃ©ploiement Docker

### Pourquoi Docker ?

**Analogie** : Docker = Un **conteneur de transport maritime**

Sans Docker :
- âŒ "Ã‡a marche sur mon PC mais pas sur le serveur"
- âŒ "Il manque une bibliothÃ¨que Python"
- âŒ "La version n'est pas la bonne"

Avec Docker :
- âœ… Tout est emballÃ© dans le conteneur
- âœ… Fonctionne partout de la mÃªme faÃ§on
- âœ… Facile Ã  dÃ©marrer : `docker compose up`

### Architecture Docker

```
ğŸ³ Conteneur 1 : Agent Datadog
   â†’ Collecte les mÃ©triques
   â†’ Envoie Ã  Datadog Cloud
   
ğŸ³ Conteneur 2 : Pipeline Python
   â†’ Lit le CSV
   â†’ Transforme les donnÃ©es
   â†’ Envoie les stats Ã  l'agent
   
ğŸŒ RÃ©seau Docker
   â†’ Les 2 conteneurs communiquent
```

---

## ğŸ“¸ Images SuggÃ©rÃ©es

### 1. Architecture SimplifiÃ©e
Un schÃ©ma avec 3 boÃ®tes et des flÃ¨ches :
```
[ğŸ“„ CSV EntrÃ©e] â†’ [ğŸ¤– Robot Python] â†’ [ğŸ“„ CSV Sortie]
                        â†“
                   [ğŸ“Š Datadog]
```

### 2. Avant/AprÃ¨s
Capture cÃ´te Ã  cÃ´te des fichiers CSV pour montrer la transformation

### 3. Dashboard Datadog
Tableau de bord colorÃ© avec graphiques et indicateurs

### 4. Logs dans le Terminal
Terminal avec messages "Pipeline started" et "Pipeline finished successfully"

---

## âœ… RÃ©sultats Concrets

### Performance

ğŸ¯ **60 lignes traitÃ©es en 0.25 seconde**
- Ã‰quivalent de 240 lignes par seconde
- Temps de traitement moyen : 0.01 ms par ligne
- 100% de rÃ©ussite

### FiabilitÃ©

ğŸ›¡ï¸ **SystÃ¨me robuste avec 3 niveaux de protection** :
1. **VÃ©rification avant traitement** : Le fichier existe-t-il ?
2. **ContrÃ´le pendant** : Chaque ligne est-elle valide ?
3. **Validation aprÃ¨s** : Le fichier de sortie est-il correct ?

### TraÃ§abilitÃ©

ğŸ“‹ **Chaque exÃ©cution est identifiÃ©e** :
- ID unique : `exec:8469c7c5`
- Tous les logs et mÃ©triques sont liÃ©s
- Permet de retrouver ce qui s'est passÃ© Ã  un moment prÃ©cis

---

## ğŸ“ Ce Que Ce Projet DÃ©montre

### CompÃ©tences Techniques

1. **Automatisation** : CrÃ©er des processus qui tournent seuls
2. **QualitÃ©** : VÃ©rifier et valider les donnÃ©es
3. **Surveillance** : Savoir ce qui se passe en temps rÃ©el
4. **Containerisation** : Empaqueter une application pour la production

### Valeur Business

ğŸ’° **ROI (Retour sur Investissement)** :
- **Temps gagnÃ©** : Plus besoin de traiter manuellement
- **FiabilitÃ©** : Moins d'erreurs humaines
- **RapiditÃ©** : 240 lignes/seconde vs traitement manuel
- **VisibilitÃ©** : On sait toujours oÃ¹ on en est

### Ã‰volutivitÃ©

ğŸš€ **PrÃªt pour la mise Ã  l'Ã©chelle** :
- âœ… Fonctionne sur 60 lignes
- âœ… Peut traiter 60 000 lignes
- âœ… Peut Ãªtre dÃ©ployÃ© sur Azure Cloud
- âœ… Peut tourner 24/7 automatiquement

---

## ğŸ”„ Migration vers Azure Cloud

### La Prochaine Ã‰tape

Ce projet **local** (sur votre ordinateur) est la **maquette** d'un systÃ¨me **production** (dans le cloud).

**Analogie** : C'est comme construire une **maquette de pont** avant de construire le vrai pont !

### Correspondance Local â†’ Cloud

| ğŸ  Version Locale | â˜ï¸ Version Cloud Azure |
|-------------------|----------------------|
| Script Python sur PC | Azure Data Factory |
| Fichier CSV local | Azure Blob Storage |
| Docker local | Azure Container Instances |
| Datadog Dashboard | Azure Monitor |

**Le code reste le mÃªme**, seul l'environnement change !

---

## ğŸ‘¥ Ã€ Qui Ã‡a Sert ?

### Cas d'Usage RÃ©els

1. **Service RH** : Traiter automatiquement les relevÃ©s de prÃ©sence
2. **Service Finance** : Consolider les rapports de ventes journaliers
3. **Service IT** : Analyser les logs de connexion
4. **Service Client** : Extraire les statistiques de satisfaction

### Exemple Concret Mercedes-Benz

Imaginons l'utilisation dans un contexte automobile :
- **EntrÃ©e** : Logs des capteurs de camions (tempÃ©rature, vitesse, GPS)
- **Traitement** : Enrichissement avec donnÃ©es mÃ©tÃ©o et trafic
- **Sortie** : Alertes prÃ©dictives de maintenance
- **Surveillance** : Dashboard temps rÃ©el du parc de vÃ©hicules

---

## ğŸ“¦ Livrables du Projet

### Ce Qui Est Fourni

- âœ… **Code source complet** : PrÃªt Ã  Ãªtre exÃ©cutÃ©
- âœ… **Configuration Docker** : DÃ©ploiement en 1 commande
- âœ… **Documentation dÃ©taillÃ©e** : Comment l'utiliser
- âœ… **Exemples de donnÃ©es** : Pour tester immÃ©diatement
- âœ… **Logs et mÃ©triques** : Visibles dans Datadog

### Comment L'Utiliser

```bash
# 1. TÃ©lÃ©charger le projet
git clone [repo]

# 2. Configurer votre clÃ© Datadog
# Ã‰diter le fichier .env

# 3. Lancer
docker compose up

# 4. Voir les rÃ©sultats
# â†’ Fichier : data/output/events_processed.csv
# â†’ Dashboard : app.datadoghq.eu
```

---

## ğŸ¯ Points ClÃ©s Ã  Retenir

### En 3 Phrases

1. ğŸ¤– **Un robot lit un fichier, ajoute des infos utiles, et crÃ©e un nouveau fichier**
2. ğŸ“Š **Un systÃ¨me de surveillance (Datadog) vÃ©rifie que tout fonctionne bien**
3. ğŸ“¦ **Tout est empaquetÃ© dans Docker pour fonctionner partout de la mÃªme faÃ§on**

### Pourquoi C'est Important

- ğŸ’¼ **Pour l'entreprise** : Gain de temps et fiabilitÃ©
- ğŸ“ **Pour l'apprentissage** : Comprendre les pipelines de donnÃ©es modernes
- ğŸš€ **Pour la carriÃ¨re** : CompÃ©tences demandÃ©es en DevOps/Data Engineering

---

## ğŸ‘¤ Auteur

**Juvet**  
DevOps Engineer â€“ Mercedes-Benz Trucks Molsheim

*Projet rÃ©alisÃ© dans le cadre du Bootcamp ObservabilitÃ© & Data*  
*PÃ©riode : 27 dÃ©cembre 2025 â†’ 4 janvier 2026*
